{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "using Flux: train!, @epochs\n",
    "using Flux.Tracker: gradient, update!\n",
    "using Printf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `gradient`\n",
    "\n",
    "Returns the \"rate of change\" of the function at the given values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "d2f (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(x) = 3x^2 + 2x + 1\n",
    "df(x) = gradient(f, x; nest=true)[1] # 6x + 2\n",
    "d2f(x) = gradient(df, x)[1]          # 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1        8.0 (tracked)\n",
      "   2       14.0 (tracked)\n",
      "   3       20.0 (tracked)\n",
      "   4       26.0 (tracked)\n",
      "   5       32.0 (tracked)\n",
      "   6       38.0 (tracked)\n",
      "   7       44.0 (tracked)\n",
      "   8       50.0 (tracked)\n",
      "   9       56.0 (tracked)\n",
      "  10       62.0 (tracked)\n"
     ]
    }
   ],
   "source": [
    "for i in 1:10\n",
    "    @printf(\"%4d %20s\\n\", i, df(i))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1        6.0 (tracked)\n",
      "   2        6.0 (tracked)\n",
      "   3        6.0 (tracked)\n",
      "   4        6.0 (tracked)\n",
      "   5        6.0 (tracked)\n",
      "   6        6.0 (tracked)\n",
      "   7        6.0 (tracked)\n",
      "   8        6.0 (tracked)\n",
      "   9        6.0 (tracked)\n",
      "  10        6.0 (tracked)\n"
     ]
    }
   ],
   "source": [
    "for i in 1:10\n",
    "    @printf(\"%4d %20s\\n\", i, d2f(i))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.0 (tracked), 3.0 (tracked))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(a, b) = a*b\n",
    "# This will flip the arguments, because the \"rate of change\" of each depends on the other.\n",
    "gradient(f, 3, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Example\n",
    "\n",
    "Here we train a \"neural network\" with 5 inputs and 2 outputs. There are no hidden layers, so I'm not sure if this is actually considered a neural network.\n",
    "\n",
    "Each of the two outputs is a weighted combination of the inputs plus a bias.\n",
    "\n",
    "We are training on a single data point of 5 parameters (`x`) and a single target of 2 parameters (`y`). Thus, we should be able to fit the model perfectly and get a loss very close to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.046756570082112"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = rand(2, 5)\n",
    "b = rand(2)\n",
    "\n",
    "predict(x) = W*x .+ b\n",
    "\n",
    "function loss(x, y)\n",
    "    ŷ = predict(x)\n",
    "    sum((y .- ŷ).^2)\n",
    "end\n",
    "\n",
    "x, y = rand(5), rand(2)\n",
    "\n",
    "loss(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tracked 2-element Array{Float64,1}:\n",
       " 0.3948092380303805\n",
       " 0.5967093463697652"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = param(W)\n",
    "b = param(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.451586131\n",
      "0.194820878\n",
      "0.084048583\n",
      "0.036259791\n",
      "0.015643005\n",
      "0.006748622\n",
      "0.002911454\n",
      "0.001256044\n",
      "0.000541876\n",
      "0.000233773\n"
     ]
    }
   ],
   "source": [
    "for epoch in 1:10\n",
    "    gradients = gradient(() -> loss(x, y), params(W, b))\n",
    "\n",
    "    update!(W, -0.1*gradients[W])\n",
    "    update!(b, -0.1*gradients[b])\n",
    "\n",
    "    @printf(\"%.9f\\n\", loss(x, y))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Julia Closures\n",
    "\n",
    "Julia closures are a little different. You need to know this to understand some of these examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "function adder(n)\n",
    "    x -> n + x\n",
    "end\n",
    "\n",
    "add6 = adder(6)\n",
    "println(add6(5))\n",
    "println(add6.n)  # Note that the variables in the closure are available as attributes of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "struct StructAdder\n",
    "    n\n",
    "end\n",
    "\n",
    "(s::StructAdder)(x) = s.n + x\n",
    "\n",
    "add6 = StructAdder(6)\n",
    "println(add6(5))\n",
    "println(add6.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layers\n",
    "\n",
    "Here we build and train a `5 * 3 * 2` neural network, with a sigmoid function. Again, we're training on a single data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tracked 2-element Array{Float64,1}:\n",
       "  0.3517323725917125 \n",
       " -0.23742354870093552"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function linear(in, out)\n",
    "    W = param(randn(out, in))\n",
    "    b = param(randn(out))\n",
    "    x -> W*x .+ b\n",
    "end\n",
    "\n",
    "linear1 = linear(5, 3)\n",
    "linear2 = linear(3, 2)\n",
    "\n",
    "model(x) = linear2(σ.(linear1(x)))\n",
    "\n",
    "model(rand(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0733103791941518 (tracked)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function loss(x, y)\n",
    "    ŷ = model(x)\n",
    "    sum((y .- ŷ).^2)\n",
    "end\n",
    "\n",
    "x, y = randn(5), randn(2)\n",
    "\n",
    "loss(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.274020578\n",
      "0.069499191\n",
      "0.017516294\n",
      "0.004416267\n",
      "0.001118774\n",
      "0.000285316\n",
      "0.000073272\n",
      "0.000018939\n",
      "0.000004923\n",
      "0.000001286\n"
     ]
    }
   ],
   "source": [
    "for epoch in 1:10\n",
    "    gradients = gradient(() -> loss(x, y), params(linear1.W, linear1.b, linear2.W, linear2.b))\n",
    "    \n",
    "    update!(linear1.W, -0.1*gradients[linear1.W])\n",
    "    update!(linear1.b, -0.1*gradients[linear1.b])\n",
    "    update!(linear2.W, -0.1*gradients[linear2.W])\n",
    "    update!(linear2.b, -0.1*gradients[linear2.b])\n",
    "    \n",
    "    @printf(\"%.9f\\n\", loss(x, y))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `train!`\n",
    "\n",
    "https://fluxml.ai/Flux.jl/stable/training/training/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9954732270380444 (tracked)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = randn(5), randn(2)\n",
    "\n",
    "loss(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.181943397\n",
      "0.482464323\n",
      "0.201011953\n",
      "0.084782366\n",
      "0.036028257\n",
      "0.015382719\n",
      "0.006588213\n",
      "0.002827619\n",
      "0.001215429\n",
      "0.000523031\n"
     ]
    }
   ],
   "source": [
    "for epoch in 1:10\n",
    "    train!(loss, params(linear1.W, linear1.b, linear2.W, linear2.b), [(x, y)], Descent())\n",
    "    @printf(\"%.9f\\n\", loss(x, y))\n",
    "end "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Chain`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Dense(10, 5, NNlib.relu), Dense(5, 2, NNlib.relu), Dense(2, 2))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = Chain(\n",
    "    Dense(10, 5, relu),\n",
    "    Dense(5, 2, relu),\n",
    "    Dense(2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss2 (generic function with 1 method)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = randn(10, 15), randn(2, 15)\n",
    "\n",
    "loss2(x, y) = Flux.mse(model2(x), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.813097557\n",
      "2.785530979\n",
      "2.758332369\n",
      "2.731498482\n",
      "2.705067583\n",
      "2.679022002\n",
      "2.653334964\n",
      "2.628001345\n",
      "2.603012662\n",
      "2.578365758\n",
      "2.554058211\n"
     ]
    }
   ],
   "source": [
    "@printf(\"%.9f\\n\", loss2(x, y))\n",
    "\n",
    "for epoch in 1:10\n",
    "    train!(loss2, params(model2), [(x, y)], ADAM())\n",
    "    @printf(\"%.9f\\n\", loss2(x, y))\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
