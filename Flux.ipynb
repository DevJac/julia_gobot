{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "using Flux.Tracker: gradient, update!\n",
    "using Printf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `gradient`\n",
    "\n",
    "Returns the \"rate of change\" of the function at the given values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "d2f (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(x) = 3x^2 + 2x + 1\n",
    "df(x) = gradient(f, x; nest=true)[1] # 6x + 2\n",
    "d2f(x) = gradient(df, x)[1]          # 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1        8.0 (tracked)\n",
      "   2       14.0 (tracked)\n",
      "   3       20.0 (tracked)\n",
      "   4       26.0 (tracked)\n",
      "   5       32.0 (tracked)\n",
      "   6       38.0 (tracked)\n",
      "   7       44.0 (tracked)\n",
      "   8       50.0 (tracked)\n",
      "   9       56.0 (tracked)\n",
      "  10       62.0 (tracked)\n"
     ]
    }
   ],
   "source": [
    "for i in 1:10\n",
    "    @printf(\"%4d %20s\\n\", i, df(i))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1        6.0 (tracked)\n",
      "   2        6.0 (tracked)\n",
      "   3        6.0 (tracked)\n",
      "   4        6.0 (tracked)\n",
      "   5        6.0 (tracked)\n",
      "   6        6.0 (tracked)\n",
      "   7        6.0 (tracked)\n",
      "   8        6.0 (tracked)\n",
      "   9        6.0 (tracked)\n",
      "  10        6.0 (tracked)\n"
     ]
    }
   ],
   "source": [
    "for i in 1:10\n",
    "    @printf(\"%4d %20s\\n\", i, d2f(i))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.0 (tracked), 3.0 (tracked))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(a, b) = a*b\n",
    "# This will flip the arguments, because the \"rate of change\" of each depends on the other.\n",
    "gradient(f, 3, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Example\n",
    "\n",
    "Here we train a \"neural network\" with 5 inputs and 2 outputs. There are no hidden layers, so I'm not sure if this is actually considered a neural network.\n",
    "\n",
    "Each of the two outputs is a weighted combination of the inputs plus a bias.\n",
    "\n",
    "We are training on a single data point of 5 parameters (`x`) and a single target of 2 parameters (`y`). Thus, we should be able to fit the model perfectly and get a loss very close to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.42893500241505"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = rand(2, 5)\n",
    "b = rand(2)\n",
    "\n",
    "predict(x) = W*x .+ b\n",
    "\n",
    "function loss(x, y)\n",
    "    ŷ = predict(x)\n",
    "    sum((y .- ŷ).^2)\n",
    "end\n",
    "\n",
    "x, y = rand(5), rand(2)\n",
    "\n",
    "loss(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tracked 2-element Array{Float64,1}:\n",
       " 0.19922442900268655\n",
       " 0.06654976390275724"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = param(W)\n",
    "b = param(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.732399055\n",
      "0.220840976\n",
      "0.066590387\n",
      "0.020079062\n",
      "0.006054458\n",
      "0.001825607\n",
      "0.000550477\n",
      "0.000165986\n",
      "0.000050050\n",
      "0.000015092\n"
     ]
    }
   ],
   "source": [
    "for epoch in 1:10\n",
    "    gradients = gradient(() -> loss(x, y), params(W, b))\n",
    "\n",
    "    update!(W, -0.1*gradients[W])\n",
    "    update!(b, -0.1*gradients[b])\n",
    "\n",
    "    @printf(\"%.9f\\n\", loss(x, y))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Julia Closures\n",
    "\n",
    "Julia closures are a little different. You need to know this to understand some of these examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "function adder(n)\n",
    "    x -> n + x\n",
    "end\n",
    "\n",
    "add6 = adder(6)\n",
    "println(add6(5))\n",
    "println(add6.n)  # Note that the variables in the closure are available as attributes of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "struct StructAdder\n",
    "    n\n",
    "end\n",
    "\n",
    "(s::StructAdder)(x) = s.n + x\n",
    "\n",
    "add6 = StructAdder(6)\n",
    "println(add6(5))\n",
    "println(add6.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layers\n",
    "\n",
    "Here we build and train a `5 * 3 * 2` neural network, with a sigmoid function. Again, we're training on a single data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tracked 2-element Array{Float64,1}:\n",
       "  1.3618386843392067\n",
       " -1.16603062486448  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function linear(in, out)\n",
    "    W = param(randn(out, in))\n",
    "    b = param(randn(out))\n",
    "    x -> W*x .+ b\n",
    "end\n",
    "\n",
    "linear1 = linear(5, 3)\n",
    "linear2 = linear(3, 2)\n",
    "\n",
    "model(x) = linear2(σ.(linear1(x)))\n",
    "\n",
    "model(rand(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.737350431363238 (tracked)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function loss(x, y)\n",
    "    ŷ = model(x)\n",
    "    sum((y .- ŷ).^2)\n",
    "end\n",
    "\n",
    "x, y = randn(5), randn(2)\n",
    "\n",
    "loss(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.777015226\n",
      "2.134103197\n",
      "0.787719589\n",
      "0.290210032\n",
      "0.106760511\n",
      "0.039235980\n",
      "0.014410982\n",
      "0.005291045\n",
      "0.001942195\n",
      "0.000712832\n"
     ]
    }
   ],
   "source": [
    "for _ in 1:10\n",
    "    gradients = gradient(() -> loss(x, y), params(linear1.W, linear1.b, linear2.W, linear2.b))\n",
    "    \n",
    "    update!(linear1.W, -0.1*gradients[linear1.W])\n",
    "    update!(linear1.b, -0.1*gradients[linear1.b])\n",
    "    update!(linear2.W, -0.1*gradients[linear2.W])\n",
    "    update!(linear2.b, -0.1*gradients[linear2.b])\n",
    "    \n",
    "    @printf(\"%.9f\\n\", loss(x, y))\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
